{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 0) Colab 런타임에 필요한 라이브러리 설치\n",
        "# ================================\n",
        "!pip install -q torch torchvision torcheval tqdm\n",
        "!pip install -q torch torchvision torcheval\n",
        "\n",
        "# ================================\n",
        "# 1) 필요한 라이브러리 불러오기\n",
        "# ================================\n",
        "import os, random, shutil\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchvision.transforms import RandAugment\n",
        "from torchvision.utils import save_image\n",
        "from torcheval.metrics import MulticlassAccuracy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ================================\n",
        "# 2) 시드 고정 => 실험의 재현성을 확보하기 위해 사용함.\n",
        "# ================================\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "seed_everything(42)\n",
        "\n",
        "# ================================\n",
        "# 3) 경로 설정\n",
        "# ================================\n",
        "original_dir = '/kaggle/input/eyeanemia'  # 원본 이미지\n",
        "aug_root     = '/content/aug_fold'        # Fold별 증강 이미지\n",
        "os.makedirs(aug_root, exist_ok=True)\n",
        "\n",
        "# ================================\n",
        "# 4) 원본 이미지 리스트 수집\n",
        "# ================================\n",
        "all_images, all_labels = [], []\n",
        "for idx, label in enumerate(sorted(os.listdir(original_dir))):\n",
        "    folder = os.path.join(original_dir, label)\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith(('.jpg','jpeg','png')):\n",
        "            all_images.append(os.path.join(folder, f))\n",
        "            all_labels.append(idx)\n",
        "\n",
        "# ================================\n",
        "# 5) Stratified 5-Fold 세팅\n",
        "# ================================\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ================================\n",
        "# 6) Transform 정의\n",
        "# ================================\n",
        "# 이미지 정규화를 위한 평균과 표준편차 (일반적으로 ImageNet 통계 사용)\n",
        "mean, std = [0.485,0.456,0.406], [0.229,0.224,0.225]\n",
        "# 학습 데이터 전처리 및 기본 증강 파이프라인 정의\n",
        "#train_transform: 매 Epoch/Batch마다 원본 학습 이미지에 동적으로 적용되는 기본 증강\n",
        "#val_transform: 검증 이미지에 적용되는 기본적인 전처리 (증강 없음)\n",
        "#strong_aug: 각 Fold 학습 시작 전, 원본 학습 이미지 일부를 변환하여 새로운 증강 이미지 파일로 저장하고, 이렇게 생성된 증강 이미지를 학습 데이터셋에 추가하는 데 사용되는 강한 증강\n",
        "\n",
        "# Resize -> CenterCrop -> RandAugment (랜덤 변환 2개 적용, 강도 9) -> RandomHorizontalFlip -> ToTensor -> Normalize\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224), # 이미지 크기 조정\n",
        "    RandAugment(num_ops=2, magnitude=9),             # RandAugment 적용\n",
        "    transforms.RandomHorizontalFlip(),               # 좌우 반전\n",
        "    transforms.ToTensor(), transforms.Normalize(mean,std), # Tensor 변환 및 정규화\n",
        "])\n",
        "\n",
        "# 검증 데이터 전처리 파이프라인 정의 (증강 없음)\n",
        "# Resize -> CenterCrop -> ToTensor -> Normalize\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224), # 이미지 크기 조정\n",
        "    transforms.ToTensor(), transforms.Normalize(mean,std), # Tensor 변환 및 정규화\n",
        "])\n",
        "\n",
        "# Fold별 데이터 증강을 위한 강한 증강 파이프라인 정의\n",
        "# 이 증강은 학습 루프 시작 전에 별도로 적용하여 추가 학습 데이터를 생성하는 데 사용됩니다.\n",
        "# Resize -> CenterCrop -> RandomRotation -> RandomHorizontalFlip -> RandomAffine -> ToTensor\n",
        "strong_aug = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224), # 이미지 크기 조정\n",
        "    transforms.RandomRotation(15),                   # 랜덤 회전 (최대 15도)\n",
        "    transforms.RandomHorizontalFlip(),               # 좌우 반전\n",
        "    transforms.RandomAffine(5, translate=(0.03,0.03), shear=5), # Affine 변환 (회전, 이동, 전단)\n",
        "    transforms.ToTensor()                            # Tensor 변환\n",
        "])\n",
        "\n",
        "# ================================\n",
        "# 7) Focal Loss - 데이터셋의 클래스 불균형을 해결하기 위해 사용 -> 쉬운 샘플에 대한 손실 감소, 어려운 샘플에 대한 손실 증가 => 불균형이 있는 데이터셋에서 소수 클래스에 대한 모델의 학습 성능 개선을 위해 넣음\n",
        "# ================================\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "    def forward(self, x, y):\n",
        "        logp = -self.ce(x, y)\n",
        "        p = torch.exp(logp)\n",
        "        return -(1 - p) ** self.gamma * logp\n",
        "\n",
        "# ================================\n",
        "# 8) 5-Fold 학습\n",
        "# ================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "best_fold_accs = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(all_images, all_labels), 1):\n",
        "    print(f\"\\n===== Fold {fold} =====\")\n",
        "\n",
        "    # 8.1) 원본 데이터셋 분리\n",
        "    full_orig_train = datasets.ImageFolder(original_dir, transform=train_transform)\n",
        "    train_orig_ds   = Subset(full_orig_train, train_idx)\n",
        "    full_orig_val   = datasets.ImageFolder(original_dir, transform=val_transform)\n",
        "    val_ds          = Subset(full_orig_val, val_idx)\n",
        "\n",
        "    # 8.2) Fold별 증강 데이터 생성\n",
        "    fold_aug_dir = os.path.join(aug_root, f\"fold{fold}\")\n",
        "    if os.path.exists(fold_aug_dir):\n",
        "        shutil.rmtree(fold_aug_dir)\n",
        "    for idx_i in train_idx:\n",
        "        img_path = all_images[idx_i]\n",
        "        lbl      = all_labels[idx_i]\n",
        "        img      = Image.open(img_path).convert('RGB')\n",
        "        out_cls  = os.path.join(fold_aug_dir, str(lbl))\n",
        "        os.makedirs(out_cls, exist_ok=True)\n",
        "        for j in range(5):\n",
        "            save_image(strong_aug(img),\n",
        "                       os.path.join(out_cls, f\"{idx_i}_{j}.jpg\"))\n",
        "\n",
        "    train_aug_ds = datasets.ImageFolder(fold_aug_dir, transform=train_transform)\n",
        "\n",
        "    # 8.3) 최종 학습용 데이터셋\n",
        "    train_ds = ConcatDataset([train_orig_ds, train_aug_ds])\n",
        "\n",
        "    # 8.4) DataLoader\n",
        "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,    batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # 8.5) 모델 정의\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "    for name, param in model.named_parameters():\n",
        "        if not (name.startswith('layer3') or name.startswith('layer4') or name.startswith('fc')):\n",
        "            param.requires_grad = False\n",
        "    nf = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.3), nn.Linear(nf,128),\n",
        "        nn.ReLU(True),   nn.Dropout(0.3),\n",
        "        nn.Linear(128,2)\n",
        "    )\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                           lr=1e-4, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5)\n",
        "    criterion = FocalLoss(gamma=2)\n",
        "\n",
        "    # 8.6) Epoch 루프\n",
        "    best_acc, patience = 0, 5\n",
        "    for epoch in range(1, 31):\n",
        "        # -- Train --\n",
        "        model.train()\n",
        "        t_acc = MulticlassAccuracy(num_classes=2).to(device)\n",
        "        t_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            lam = np.random.beta(0.2,0.2)\n",
        "            idx2 = torch.randperm(x.size(0))\n",
        "            mixed_x = lam * x + (1-lam) * x[idx2]\n",
        "            y_a, y_b = y, y[idx2]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            out = model(mixed_x)\n",
        "            loss = lam * criterion(out, y_a) + (1-lam) * criterion(out, y_b)\n",
        "            loss.backward(); optimizer.step()\n",
        "            t_loss += loss.item()*x.size(0)\n",
        "            t_acc.update(out.argmax(1), y)\n",
        "        scheduler.step()\n",
        "        train_loss = t_loss / len(train_ds); train_acc = t_acc.compute().item()\n",
        "\n",
        "        # -- Val --\n",
        "        model.eval()\n",
        "        v_acc = MulticlassAccuracy(num_classes=2).to(device)\n",
        "        v_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                loss = criterion(out, y)\n",
        "                v_loss += loss.item()*x.size(0)\n",
        "                v_acc.update(out.argmax(1), y)\n",
        "        val_loss = v_loss/len(val_ds); val_acc = v_acc.compute().item()\n",
        "\n",
        "        print(f\"Epoch {epoch:02d} TL {train_loss:.3f} TA {train_acc:.3f} | \"\n",
        "              f\"VL {val_loss:.3f} VA {val_acc:.3f}\")\n",
        "\n",
        "        # -- Early Stopping & Save --\n",
        "        if val_acc > best_acc:\n",
        "            best_acc, patience = val_acc, 5\n",
        "            torch.save(model.state_dict(), f\"best_fold{fold}.pth\")\n",
        "        else:\n",
        "            patience -= 1\n",
        "            if patience == 0:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    print(f\"Fold {fold} best_val_acc: {best_acc:.3f}\")\n",
        "    best_fold_accs.append(best_acc)\n",
        "\n",
        "# ================================\n",
        "# 9) 전체 Fold 평균 출력\n",
        "# ================================\n",
        "print(f\"\\n5-Fold Mean val_acc: {np.mean(best_fold_accs):.3f}\")\n"
      ],
      "metadata": {
        "id": "0hjOoQUu24E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 라이브러리 임포트\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 2. 디바이스 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running on: {device}\")\n",
        "\n",
        "# 3. 클래스 레이블 맵핑\n",
        "# 학습 시 ImageFolder 순서대로 0='Anemia', 1='Non Anemia' 이라 가정\n",
        "label_map = {0: \"Anemia\", 1: \"Non-Anemia\"}\n",
        "\n",
        "# 4. 모델 정의 (학습과 동일한 구조)\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# layer1,2는 freeze, layer3,4,fc는 fine-tune했던 상태\n",
        "for name, param in model.named_parameters():\n",
        "    if not (name.startswith(\"layer3\") or name.startswith(\"layer4\") or name.startswith(\"fc\")):\n",
        "        param.requires_grad = False\n",
        "\n",
        "# fc 헤드: Dropout(0.3) → 128 → ReLU → Dropout(0.3) → 2-way Linear\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(num_ftrs, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(128, 2)\n",
        ")\n",
        "\n",
        "# 5. 학습된 가중치 불러오기\n",
        "checkpoint_path = \"best_fold3.pth\"  # 학습 스크립트에서 저장된 가중치\n",
        "state_dict = torch.load(checkpoint_path, map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded and set to eval mode.\")\n",
        "\n",
        "# 6. 전처리 정의 (검증/추론용)\n",
        "IMG_SIZE = 224\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 7. 예측 함수 정의\n",
        "def predict_image(image_path):\n",
        "    # 1) 이미지 로드 & 전처리\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    x = val_transform(image).unsqueeze(0).to(device)  # (1, C, H, W)\n",
        "\n",
        "    # 2) 추론\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)               # (1, 2)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().squeeze(0)  # (2,)\n",
        "        conf, pred = torch.max(probs, dim=0)  # 최고 확률과 인덱스\n",
        "\n",
        "    # 3) 결과 출력\n",
        "    print(f\"Image         : {os.path.basename(image_path)}\")\n",
        "    print(f\"Predicted cls : {label_map[pred.item()]}\")\n",
        "    print(f\"Confidence    : {conf.item():.4f} ({pred.item()} vs {1-pred.item()})\")\n",
        "    return pred.item(), conf.item()\n",
        "\n",
        "# 8. 사용 예시\n",
        "# 테스트할 이미지 경로로 수정하세요\n",
        "test_image_path = \"/content/1000092724.jpg\"\n",
        "predict_image(test_image_path)\n"
      ],
      "metadata": {
        "id": "I40RoK8q3Kw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def evaluate_metrics(model, dataloader, device):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            preds = out.argmax(dim=1)\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1  = f1_score(y_true, y_pred)\n",
        "    return acc, prec, rec, f1\n",
        "\n",
        "# --- Fold 루프의 마지막 부분에 삽입 ---\n",
        "# (train, val dataloader, model 정의 후)\n",
        "torch.save(model.state_dict(), f\"best_fold{fold}.pth\")\n",
        "print(f\"Fold {fold} best_val_acc: {best_acc:.3f}\")\n",
        "\n",
        "# 1) 베스트 모델 로드\n",
        "model.load_state_dict(torch.load(f\"best_fold{fold}.pth\", map_location=device))\n",
        "\n",
        "# 2) 원본 검증 세트에 대한 평가\n",
        "full_orig_val = datasets.ImageFolder(original_dir, transform=val_transform)\n",
        "val_ds        = Subset(full_orig_val, val_idx)\n",
        "val_loader    = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "acc, prec, rec, f1 = evaluate_metrics(model, val_loader, device)\n",
        "print(f\"Fold {fold} 평가 지표:\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1 Score : {f1:.4f}\")\n",
        "\n",
        "best_fold_accs.append(best_acc)\n"
      ],
      "metadata": {
        "id": "H39U_TYB3MVq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}